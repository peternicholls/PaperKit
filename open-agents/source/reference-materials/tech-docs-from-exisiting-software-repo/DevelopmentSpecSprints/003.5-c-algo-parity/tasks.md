---

description: "Tasks for C Algorithm Parity Testing"
---

# Tasks: C Algorithm Parity Testing

**Input**: Design documents from `/specs/003.5-c-algo-parity/`
**Prerequisites**: plan.md (required), spec.md (user stories), research.md, data-model.md, contracts/

**Tests**: Tests are mandatory. Add C unit/integration tests alongside harness code; parity runs must be reproducible and validated.

**Organization**: Tasks grouped by user story for independent implementation and testing.

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Establish folders and configs needed before building the harness (pure C focus).

- [X] T001 Create corpus directory scaffold and placeholder keep-alive in specs/003.5-c-algo-parity/corpus/.gitkeep
- [X] T002 Add corpus JSON schema defining InputCase and config fields in specs/003.5-c-algo-parity/corpus/schema.json
- [X] T003 Add default tolerance/config template (abs/rel, deltaE) in specs/003.5-c-algo-parity/config/tolerances.example.json
- [X] T004 Document required C toolchain (clang/gcc C99) and test commands in specs/003.5-c-algo-parity/quickstart.md
- [X] T005 [P] Add artifacts root with README for run outputs in specs/003.5-c-algo-parity/artifacts/README.md

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core plumbing that all user stories rely on (types, validation, build inputs) in C, with optional Python for stats-only postprocessing.

- [X] T006 Initialize C parity runner workspace with Makefile (build/run/test targets) in specs/003.5-c-algo-parity/tools/parity-runner/
- [X] T007 [P] Define shared C headers for InputCase, EngineOutput, ComparisonResult, RunReport in specs/003.5-c-algo-parity/tools/parity-runner/include/types.h
- [X] T008 [P] Implement corpus and tolerance JSON parsing/validation in C in specs/003.5-c-algo-parity/tools/parity-runner/src/json_validation.c
- [X] T009 [P] Add C CLI entry (arg parsing for cases, tolerances, artifacts path) in specs/003.5-c-algo-parity/tools/parity-runner/src/main.c
- [X] T010 Vendor minimal C JSON dependency (pin cJSON) and wire Makefile to build parity-runner binary
- [X] T031 Define and publish default tolerances (abs L/a/b=1e-4, Î”E<=0.5, rel L/a/b=1e-3) plus override policy in specs/003.5-c-algo-parity/config/README.md and tolerances.example.json
- [X] T032 Add corpus versioning policy (`vYYYYMMDD.n`) and validation in specs/003.5-c-algo-parity/tools/parity-runner/src/json_validation.c and specs/003.5-c-algo-parity/config/README.md
- [X] T039 Add C unit tests for JSON parsing/validation, tolerances application, and OKLab comparison math in specs/003.5-c-algo-parity/tools/parity-runner/tests/
- [X] T040 Add C integration test that runs parity-runner against a tiny corpus and asserts deterministic pass/fail outputs in specs/003.5-c-algo-parity/tools/parity-runner/tests/
- [X] T041 Wire tests into Makefile (`make test`) and ensure CI target executes them before reporting success

**Checkpoint**: Foundation readyâ€”user stories can proceed.

---

## Phase 3: User Story 1 - Parity Report For Both Engines (Priority: P1) ðŸŽ¯ MVP

**Goal**: Run corpus through two C builds (canonical C core and wasm-target sources compiled as plain C), normalize outputs, and emit deterministic pass/fail report with per-case deltas.

**Independent Test**: Run the C CLI on the default corpus to produce report and summary without other stories.

### Implementation for User Story 1

- [X] T011 [P] Add default corpus cases (baseline, boundary, seeded) in specs/003.5-c-algo-parity/corpus/default.json
- [X] T012 [P] Build C reference JSON emitter binary (wrap ColorJourney.c) in Tests/Parity/parity_c_runner.c
- [X] T013 [P] Build alternate C binary from Sources/wasm as plain C (matching flags) in Tests/Parity/parity_wasm_as_c_runner.c
- [X] T014 [P] Implement execution wrapper for canonical C binary (spawn parity_c_runner, parse JSON) in specs/003.5-c-algo-parity/tools/parity-runner/src/exec_c.c
- [X] T015 [P] Implement execution wrapper for wasm-sources-as-C binary in specs/003.5-c-algo-parity/tools/parity-runner/src/exec_c_alt.c
- [X] T016 Normalize both outputs to OKLab double precision and compare with tolerances in specs/003.5-c-algo-parity/tools/parity-runner/src/compare.c
- [X] T017 Generate run report with summary totals and per-case results in specs/003.5-c-algo-parity/tools/parity-runner/src/report.c
- [X] T018 Wire CLI flow to run corpus, collect results, and write artifacts under specs/003.5-c-algo-parity/artifacts/<runId>/ in specs/003.5-c-algo-parity/tools/parity-runner/src/main.c
- [X] T033 Add edge-case corpus fixtures (extremes, malformed inputs with expected rejections, platform-flag notes) in specs/003.5-c-algo-parity/corpus/edge-cases.json
- [X] T034 Capture run provenance (corpus version, commits, build flags, platform) in report header and artifacts in specs/003.5-c-algo-parity/tools/parity-runner/src/report.c
- [X] T035 Enforce pass-rate gate (>=95%) and fail runs below threshold in specs/003.5-c-algo-parity/tools/parity-runner/src/report.c
- [X] T036 Measure total runtime; fail or flag runs exceeding 10 minutes and record duration in report summary in specs/003.5-c-algo-parity/tools/parity-runner/src/main.c
- [X] T037 [P] Compute summary statistics (mean/stddev/p50/p95/p99/max) and histograms for Î”E and per-channel OKLab deltas in C; optionally export JSON for Python postprocessing in specs/003.5-c-algo-parity/tools/stats/
- [X] T042 Align alternate runner outputs and/or tolerance defaults so fixture corpus meets the configured pass gate in specs/003.5-c-algo-parity/tools/parity-runner (runners, tolerances fixtures)
- [X] T043 Capture build flags for both runners in provenance and include them in report outputs in specs/003.5-c-algo-parity/tools/parity-runner/src/report.c and artifacts

**Checkpoint**: P1 MVP delivers deterministic parity report and artifacts.

---

## Phase 4: User Story 2 - Root Cause Hints For Divergences (Priority: P2)

**Goal**: Surface top contributing differences and stage/parameter hints for failing cases.

**Independent Test**: For a failing case, report lists channel/metric magnitudes and maps to computation stage/parameter.

### Implementation for User Story 2

- [X] T019 [P] Add stage/parameter mapping metadata (e.g., channel labels, stage names) in specs/003.5-c-algo-parity/tools/parity-runner/src/stage_map.c
- [X] T020 [P] Compute per-case top contributors (OKLab components, Î”E, RGB deltas) with directionality in specs/003.5-c-algo-parity/tools/parity-runner/src/analysis.c
- [X] T021 Annotate failing cases with stage/parameter hints and include in report output in specs/003.5-c-algo-parity/tools/parity-runner/src/report.c
- [X] T022 Add focused artifact bundle per failing case (inputs, both outputs, deltas, hints) in specs/003.5-c-algo-parity/artifacts/<runId>/<caseId>/metadata.json
- [X] T038 [P] Highlight statistically significant contributors (e.g., highest Î”E/z-score channels/stages) in failure hints in specs/003.5-c-algo-parity/tools/parity-runner/src/analysis.c

**Checkpoint**: P2 delivers actionable hints per failure.

---

## Phase 5: User Story 3 - Traceable Regression Prevention (Priority: P3)

**Goal**: CI/on-demand runs fail on new divergences and persist reproducible artifacts.

**Independent Test**: CI job fails on new drift and saves artifacts per failing case.

### Implementation for User Story 3

- [X] T023 Add CLI options for corpus filters, tolerance overrides, and artifact retention policy in specs/003.5-c-algo-parity/tools/parity-runner/src/main.c
- [X] T024 [P] Ensure CI workflow runs C parity binary and persists provenance (commits, build flags, platform, corpus version) alongside uploaded artifacts in .github/workflows/parity.yml
- [X] T025 [P] Add CI workflow to run parity suite and upload artifacts on failure in .github/workflows/parity.yml
- [X] T026 Persist artifacts directory structure with .gitkeep and README in specs/003.5-c-algo-parity/artifacts/.gitkeep

**Checkpoint**: P3 enables regression prevention with artifacts.

---

## Phase 6: Polish & Cross-Cutting Concerns

**Purpose**: Shared improvements across stories.

- [X] T027 [P] Update operator docs with C CLI usage and report formats in specs/003.5-c-algo-parity/quickstart.md
- [X] T028 [P] Add tolerance configuration docs and examples in specs/003.5-c-algo-parity/config/README.md
- [X] T029 [P] Add schema and API references to specs/003.5-c-algo-parity/contracts/README.md
- [X] T030 Run end-to-end dry run over full corpus and capture sample report in specs/003.5-c-algo-parity/artifacts/sample-run/README.md

---

## Phase 7: Run The Parity Suite 
**Purpose**: Execute the parity suite on the full corpus to validate implementation.

- [X] T044 Run end-to-end parity suite over the full corpus using default tolerances and capture report/artifacts in full report.
- [X] T045 Make sure tests are comprehensive.

---

## Phase 8: Review & Document Findings
**Purpose**: Analyze results and document findings from the parity run.

- [X] T046 Review generated report for summary and inspect per-case artifacts for failures
- [X] T047 Analyze results and document any discrepancies or areas for improvement
- [X] T048 Write a summary of findings and next steps in specs/003.5-c-algo-parity/review.md
- [X] T049 Share results with the team for feedback and discussion
- [X] T050 Plan follow-up actions based on parity run outcomes, make preliminary evaluations of the parity between both C engine implementations

---

## Dependencies & Execution Order

- Setup (Phase 1) â†’ Foundational (Phase 2) â†’ US1 (P1) â†’ US2 (P2) â†’ US3 (P3) â†’ Polish.
- US2 depends on US1 comparison outputs; US3 depends on US1 reports and US2 hint metadata.
- Parallelizable tasks marked [P] can proceed concurrently when file paths do not conflict.

## Parallel Execution Examples

- Foundation: T007, T008, T009 can run in parallel (separate C units and Makefile wiring).
- US1: T013, T014, T015 can run in parallel after T006-T009 since they build/run separate binaries.
- US2: T019 and T020 can run in parallel; T021 depends on both.
- US3: T024 and T025 can run in parallel; T023 depends on CLI base (T009, T018).

## Implementation Strategy

- MVP first: complete Setup â†’ Foundational â†’ US1 to get deterministic parity reports.
- Incremental: add US2 for diagnostics, then US3 for CI gating and artifact retention.
- Each story is independently testable by invoking the CLI against the corpus with its respective outputs enabled.

---

## Phase 9: Swift Wrapper Parity Testing

**Status**: âœ… Complete (Phases 1-8 finished)  
**Next Phase**: See [phase-9-tasks.md](phase-9-tasks.md) for 29 Swift wrapper validation tasks (T051-T079)

Phase 9 replicates the C parity methodology but validates the Swift wrapper layer (`Sources/ColorJourney/*`). Comprehensive specification available:

- **Full Specification**: [phase-9-swift-parity.md](phase-9-swift-parity.md)
- **Detailed Tasks**: [phase-9-tasks.md](phase-9-tasks.md) (29 tasks, 5 phases)
- **API Contract**: [contracts/swift-wrapper-parity-api.yaml](contracts/swift-wrapper-parity-api.yaml)
- **Executive Summary**: [PHASE-9-SPEC-SUMMARY.md](PHASE-9-SPEC-SUMMARY.md)
- **Complete Index**: [INDEX.md](INDEX.md)
